<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Adaptive AI/ML Control Framework</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css" xintegrity="sha384-n8MVd4RsNIU0KOVEMeaM8spQKIgvplEQ7ikpBFe7loidvDiTUtblshSFdeIIRgqs" crossorigin="anonymous">
    <script src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js" xintegrity="sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzYCcm2KEiVAnZN6e4sgQgIXs2G0KHOKdst" crossorigin="anonymous"></script>
    <style>
        @import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap');
        body {
            font-family: 'Inter', sans-serif;
            background-color: #F8F7F4;
            color: #1a202c;
        }
        .nav-item {
            cursor: pointer;
            padding: 8px 16px;
            border-radius: 8px;
            transition: all 0.3s ease;
            font-weight: 500;
        }
        .nav-item-active {
            background-color: #3B82F6;
            color: white;
            box-shadow: 0 4px 6px -1px rgb(0 0 0 / 0.1), 0 2px 4px -2px rgb(0 0 0 / 0.1);
        }
        .nav-item:not(.nav-item-active):hover {
            background-color: #e0e7ff;
        }
        .content-section {
            display: none;
        }
        .content-section-active {
            display: block;
        }
        .sub-nav-item {
            cursor: pointer;
            padding: 6px 12px;
            border-radius: 6px;
            transition: background-color 0.3s ease;
            color: #4a5568;
            font-weight: 500;
        }
        .sub-nav-item-active {
            background-color: #dbeafe;
            color: #1e40af;
        }
        .tab-content {
            display: none;
        }
        .tab-content-active {
            display: block;
        }
        .chart-container {
            position: relative;
            width: 100%;
            max-width: 800px;
            margin-left: auto;
            margin-right: auto;
            height: 320px;
            max-height: 400px;
        }
        @media (min-width: 768px) {
            .chart-container {
                height: 400px;
            }
        }
        pre {
            background-color: #f3f4f6;
            border: 1px solid #e5e7eb;
            border-radius: 8px;
            padding: 16px;
            overflow-x: auto;
            color: #111827;
            font-size: 0.875rem;
        }
        code {
            font-family: 'Courier New', Courier, monospace;
        }
        .katex-display {
            overflow-x: auto;
            overflow-y: hidden;
            padding: 8px 0;
        }
    </style>
    <!-- Chosen Palette: Calm Neutrals with Tech Blue Accent -->
    <!-- Application Structure Plan: A multi-section SPA with a main top navigation bar (Intro, Architecture, Models, Research). This structure allows users to digest high-level concepts first and then delve into progressively more technical details at their own pace. The 'Models & Algorithms' section uses sub-tabs for specific technologies (LSTM, RL) to organize complex information cleanly. The 'Global Research' section also uses tabs to simulate exploring international findings. This tabbed, non-linear approach is chosen over a long scrollable page to improve user experience, reduce cognitive load, and allow for focused exploration of the dense, technical content. -->
    <!-- Visualization & Content Choices: 
    1. Framework Diagram: Info -> Goal: Organize -> Viz: HTML/CSS Diagram -> Interaction: Hover to highlight -> Justification: Provides an immediate, clear overview of the system's components without using restricted SVG.
    2. Time-Series Chart: Info -> Goal: Change -> Viz: Chart.js Line Chart -> Interaction: Button click to animate prediction -> Justification: Visually demonstrates the LSTM's predictive power in an engaging, interactive manner.
    3. RL Loop Diagram: Info -> Goal: Organize -> Viz: HTML/CSS Diagram -> Interaction: Hover for tooltips -> Justification: Breaks down the complex RL cycle into understandable, interactive parts.
    4. Code & Math: Info -> Goal: Inform -> Viz: Styled <pre> blocks & KaTeX rendering -> Interaction: None (static display) -> Justification: Directly fulfills user request for deep technical details in a readable format. KaTeX is used for proper mathematical typesetting.
    Library/Method: Chart.js for charts, KaTeX for math, all diagrams built with Tailwind CSS. -->
    <!-- CONFIRMATION: NO SVG graphics used. NO Mermaid JS used. -->
</head>
<body class="antialiased">

    <div class="min-h-screen">
        <header class="bg-white shadow-sm">
            <div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-4">
                <h1 class="text-3xl font-bold text-gray-900">Adaptive AI/ML Control Framework</h1>
                <p class="mt-1 text-gray-600">An interactive exploration of an advanced architecture for predictive analytics and system optimisation.</p>
            </div>
        </header>

        <nav class="bg-white/50 backdrop-blur-sm sticky top-0 z-10 border-b border-gray-200">
            <div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8">
                <div class="flex items-center justify-center space-x-2 sm:space-x-4 py-3">
                    <div id="nav-intro" class="nav-item nav-item-active">Introduction</div>
                    <div id="nav-architecture" class="nav-item">Architecture</div>
                    <div id="nav-models" class="nav-item">Models & Algorithms</div>
                    <div id="nav-research" class="nav-item">Global Research</div>
                </div>
            </div>
        </nav>

        <main class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-8">
            
            <section id="content-intro" class="content-section content-section-active">
                <div class="bg-white p-6 sm:p-8 rounded-xl shadow-md">
                    <h2 class="text-2xl font-bold text-gray-800 mb-4">Core Concepts of the Framework</h2>
                    <p class="text-gray-700 mb-6 leading-relaxed">
                        This section provides a high-level overview of the Adaptive AI/ML Control Framework. The primary goal of this architecture is to create a closed-loop system that continuously learns from incoming data to predict future states and make optimal control decisions. It integrates time-series forecasting with reinforcement learning to dynamically adjust system parameters, ensuring efficiency, stability, and responsiveness in complex, changing environments.
                    </p>
                    <div class="grid grid-cols-1 md:grid-cols-5 gap-8 items-center">
                        <div class="md:col-span-3">
                            <h3 class="text-xl font-semibold text-gray-800 mb-3">System Flow Diagram</h3>
                            <div class="border rounded-lg p-6 bg-slate-50">
                                <div class="space-y-4">
                                    <div class="flex items-center space-x-2">
                                        <div class="flex-shrink-0 bg-blue-100 text-blue-800 rounded-lg p-3">
                                            <span>&#x1F4BE;</span>
                                        </div>
                                        <div class="flex-grow p-3 bg-white border rounded-md shadow-sm text-center font-medium">Data Ingestion (Time-Series)</div>
                                        <div class="text-2xl font-light text-gray-400">&rarr;</div>
                                    </div>
                                    <div class="flex items-center space-x-2 justify-end">
                                        <div class="text-2xl font-light text-gray-400 transform -rotate-90 md:rotate-0">&darr;</div>
                                    </div>
                                     <div class="flex items-center space-x-2">
                                        <div class="flex-shrink-0 bg-purple-100 text-purple-800 rounded-lg p-3">
                                            <span>&#x1F50E;</span>
                                        </div>
                                        <div class="flex-grow p-3 bg-white border rounded-md shadow-sm text-center font-medium">Predictive Model (LSTM)</div>
                                        <div class="text-2xl font-light text-gray-400">&rarr;</div>
                                    </div>
                                    <div class="flex items-center space-x-2 justify-end">
                                        <div class="text-2xl font-light text-gray-400 transform -rotate-90 md:rotate-0">&darr;</div>
                                    </div>
                                     <div class="flex items-center space-x-2">
                                        <div class="flex-shrink-0 bg-green-100 text-green-800 rounded-lg p-3">
                                            <span>&#x1F916;</span>
                                        </div>
                                        <div class="flex-grow p-3 bg-white border rounded-md shadow-sm text-center font-medium">Optimisation Engine (RL)</div>
                                        <div class="text-2xl font-light text-gray-400">&rarr;</div>
                                    </div>
                                     <div class="flex items-center space-x-2 justify-end">
                                        <div class="text-2xl font-light text-gray-400 transform -rotate-90 md:rotate-0">&darr;</div>
                                    </div>
                                     <div class="flex items-center space-x-2">
                                        <div class="flex-shrink-0 bg-yellow-100 text-yellow-800 rounded-lg p-3">
                                            <span>&#x1F527;</span>
                                        </div>
                                        <div class="flex-grow p-3 bg-white border rounded-md shadow-sm text-center font-medium">Control System Action</div>
                                        <div class="text-2xl font-light text-gray-400">&rarr;</div>
                                    </div>
                                    <div class="flex items-center space-x-2 justify-end">
                                        <div class="text-2xl font-light text-gray-400 transform -rotate-90 md:rotate-0">&darr;</div>
                                    </div>
                                     <div class="flex items-center space-x-2">
                                        <div class="flex-shrink-0 bg-red-100 text-red-800 rounded-lg p-3">
                                            <span>&#x1F3AF;</span>
                                        </div>
                                        <div class="flex-grow p-3 bg-white border rounded-md shadow-sm text-center font-medium">Environment Feedback</div>
                                        <div class="text-2xl font-light text-gray-400">&#x21BA;</div>
                                    </div>
                                </div>
                            </div>
                        </div>
                        <div class="md:col-span-2 space-y-4">
                            <div>
                                <h3 class="font-semibold text-lg text-gray-800">Predictive Analytics</h3>
                                <p class="text-gray-600">Utilises Long Short-Term Memory (LSTM) networks to forecast future system states from historical time-series data, anticipating trends and potential anomalies.</p>
                            </div>
                            <div>
                                <h3 class="font-semibold text-lg text-gray-800">Dynamic Optimisation</h3>
                                <p class="text-gray-600">Employs Reinforcement Learning (RL) to determine the best sequence of actions. The RL agent learns a policy to maximize a cumulative reward, such as energy efficiency or output quality.</p>
                            </div>
                            <div>
                                <h3 class="font-semibold text-lg text-gray-800">Adaptive Control</h3>
                                <p class="text-gray-600">The combination of prediction and optimisation allows the system to adapt its control strategy in real-time, moving beyond static, rule-based systems to a truly intelligent and autonomous operation.</p>
                            </div>
                        </div>
                    </div>
                </div>
            </section>

            <section id="content-architecture" class="content-section">
                 <div class="bg-white p-6 sm:p-8 rounded-xl shadow-md">
                    <h2 class="text-2xl font-bold text-gray-800 mb-4">Architectural Deep Dive</h2>
                    <p class="text-gray-700 mb-6 leading-relaxed">
                        The framework's architecture is modular, comprising four distinct stages that form the closed-loop control system. Each component is designed for high performance and scalability, ensuring that the system can handle large volumes of data and complex decision-making processes. Explore each component below to understand its specific role and function within the overall architecture.
                    </p>
                    <div class="grid grid-cols-1 md:grid-cols-2 lg:grid-cols-4 gap-6">
                        <div class="border rounded-lg p-6 bg-slate-50 hover:shadow-lg transition-shadow">
                            <h3 class="text-xl font-semibold text-blue-800 mb-2">1. Data Ingestion Layer</h3>
                            <p class="text-gray-600">This layer is responsible for collecting, pre-processing, and normalising raw time-series data from various sensors and system logs. It ensures data quality and consistency, preparing it for the predictive model. Key steps include noise filtering, handling missing values, and feature scaling.</p>
                        </div>
                        <div class="border rounded-lg p-6 bg-slate-50 hover:shadow-lg transition-shadow">
                            <h3 class="text-xl font-semibold text-purple-800 mb-2">2. Predictive Model Layer</h3>
                            <p class="text-gray-600">At the core of this layer is an LSTM neural network. It takes the prepared time-series data as input and generates predictions for future system states over a defined horizon. These predictions form the basis for the optimisation engine's decision-making process, providing a forecast of the environment's future behavior.</p>
                        </div>
                        <div class="border rounded-lg p-6 bg-slate-50 hover:shadow-lg transition-shadow">
                            <h3 class="text-xl font-semibold text-green-800 mb-2">3. Optimisation Engine Layer</h3>
                            <p class="text-gray-600">This layer uses a Reinforcement Learning agent (e.g., Q-learning or a policy gradient method). The agent treats the predicted future states as its environment and explores various action sequences to find a policy that maximizes long-term rewards. The output is an optimal action or set of control parameters.</p>
                        </div>
                        <div class="border rounded-lg p-6 bg-slate-50 hover:shadow-lg transition-shadow">
                            <h3 class="text-xl font-semibold text-yellow-800 mb-2">4. Control & Feedback Layer</h3>
                            <p class="text-gray-600">The optimal action determined by the RL agent is translated into a command and sent to the physical or simulated system. The resulting change in the system's state is then measured, and this new data is fed back into the Ingestion Layer, closing the loop and allowing the system to continuously learn and adapt from its own actions.</p>
                        </div>
                    </div>
                </div>
            </section>

            <section id="content-models" class="content-section">
                <div class="bg-white p-6 sm:p-8 rounded-xl shadow-md">
                    <h2 class="text-2xl font-bold text-gray-800 mb-4">Models & Algorithms</h2>
                    <p class="text-gray-700 mb-6 leading-relaxed">
                        This section provides a technical examination of the core machine learning models powering the framework. Here you will find detailed explanations, mathematical formulations, interactive visualizations, and low-level code examples for both the LSTM network used for prediction and the Reinforcement Learning algorithms used for optimization.
                    </p>

                    <div class="flex items-center justify-center border-b border-gray-200 mb-6">
                        <div id="sub-nav-lstm" class="sub-nav-item sub-nav-item-active">LSTM for Prediction</div>
                        <div id="sub-nav-rl" class="sub-nav-item">Reinforcement Learning</div>
                    </div>

                    <div id="tab-content-lstm" class="tab-content tab-content-active">
                        <h3 class="text-xl font-semibold mb-4 text-purple-800">Long Short-Term Memory (LSTM) Networks</h3>
                        <p class="mb-4">LSTMs are a type of Recurrent Neural Network (RNN) specifically designed to handle long-term dependencies in sequential data. This makes them ideal for time-series forecasting. Unlike standard RNNs, LSTMs have a "memory cell" that can maintain information over long periods, controlled by three "gates": the input gate, forget gate, and output gate.</p>
                        <div class="chart-container mb-6">
                            <canvas id="lstmChart"></canvas>
                        </div>
                        <div class="text-center mb-6">
                            <button id="runPredictionBtn" class="bg-blue-500 hover:bg-blue-600 text-white font-bold py-2 px-4 rounded-lg transition-colors">Run Prediction</button>
                        </div>
                        <div class="grid grid-cols-1 md:grid-cols-2 gap-8">
                            <div>
                                <h4 class="font-semibold text-lg mb-2">Core LSTM Equations</h4>
                                <div class="space-y-4 text-sm">
                                    <div id="forget-gate"></div>
                                    <div id="input-gate"></div>
                                    <div id="cell-state"></div>
                                    <div id="output-gate"></div>
                                </div>
                            </div>
                            <div>
                                <h4 class="font-semibold text-lg mb-2">LSTM Cell Forward Pass (C++)</h4>
                                <pre><code class="language-cpp">
// Simplified C++ implementation for a single LSTM cell forward pass
#include &lt;vector&gt;
#include &lt;cmath&gt;

// Activation functions
double sigmoid(double x) { return 1.0 / (1.0 + exp(-x)); }
double tanh_activation(double x) { return tanh(x); }

struct LstmCell {
    // Weights and biases would be members here
    // Wf, Wi, Wc, Wo, Uf, Ui, Uc, Uo, bf, bi, bc, bo

    void forward(const std::vector&lt;double&gt;& input, 
                 std::vector&lt;double&gt;& h_prev, 
                 std::vector&lt;double&gt;& c_prev,
                 std::vector&lt;double&gt;& h_next, 
                 std::vector&lt;double&gt;& c_next) 
    {
        // Assume dot products and additions are handled by a helper
        // This is a conceptual representation
        
        // 1. Forget Gate
        // f_t = sigmoid(Wf * x_t + Uf * h_{t-1} + bf)
        std::vector&lt;double&gt; f_t = calculate_gate(input, h_prev, Wf, Uf, bf, sigmoid);

        // 2. Input Gate
        // i_t = sigmoid(Wi * x_t + Ui * h_{t-1} + bi)
        std::vector&lt;double&gt; i_t = calculate_gate(input, h_prev, Wi, Ui, bi, sigmoid);
        
        // 3. Candidate Cell State
        // C_tilde_t = tanh(Wc * x_t + Uc * h_{t-1} + bc)
        std::vector&lt;double&gt; C_tilde_t = calculate_gate(input, h_prev, Wc, Uc, bc, tanh_activation);

        // 4. Update Cell State
        // c_t = f_t * c_{t-1} + i_t * C_tilde_t
        c_next = element_wise_product(f_t, c_prev) + element_wise_product(i_t, C_tilde_t);

        // 5. Output Gate
        // o_t = sigmoid(Wo * x_t + Uo * h_{t-1} + bo)
        std::vector&lt;double&gt; o_t = calculate_gate(input, h_prev, Wo, Uo, bo, sigmoid);

        // 6. Update Hidden State
        // h_t = o_t * tanh(c_t)
        h_next = element_wise_product(o_t, tanh_vector(c_next));
    }
};
                                </code></pre>
                            </div>
                        </div>
                    </div>

                    <div id="tab-content-rl" class="tab-content">
                        <h3 class="text-xl font-semibold mb-4 text-green-800">Reinforcement Learning (RL)</h3>
                        <p class="mb-4">Reinforcement Learning is a paradigm of machine learning where an "agent" learns to make decisions by performing actions in an "environment" to maximize a cumulative "reward". The agent learns from the consequences of its actions, rather than from being explicitly taught. This is ideal for control problems where the optimal strategy is not known beforehand.</p>
                        
                        <div class="my-6 p-6 border rounded-lg bg-slate-50">
                             <h4 class="font-semibold text-lg mb-4 text-center">The RL Interaction Loop</h4>
                            <div class="flex flex-col md:flex-row items-center justify-around space-y-4 md:space-y-0 md:space-x-4">
                                <div class="text-center p-4 bg-white rounded-lg shadow-md">
                                    <div class="text-4xl">🤖</div><div class="font-bold mt-1">Agent</div>
                                </div>
                                <div class="flex flex-col items-center">
                                    <span class="font-medium">Action (A)</span>
                                    <span class="text-3xl text-gray-500">&rarr;</span>
                                </div>
                                <div class="text-center p-4 bg-white rounded-lg shadow-md">
                                    <div class="text-4xl">🌍</div><div class="font-bold mt-1">Environment</div>
                                </div>
                                <div class="flex flex-col items-center">
                                    <span class="font-medium">State (S), Reward (R)</span>
                                    <span class="text-3xl text-gray-500">&larr;</span>
                                </div>
                            </div>
                        </div>

                        <div class="grid grid-cols-1 md:grid-cols-2 gap-8">
                            <div>
                                <h4 class="font-semibold text-lg mb-2">The Bellman Equation</h4>
                                <p class="mb-4 text-sm text-gray-600">The core of many RL algorithms is the Bellman equation. It defines the value of being in a certain state by relating it to the values of subsequent states. For Q-learning, it defines the value of taking an action in a state:</p>
                                <div id="bellman-eq"></div>
                                <p class="mt-4 text-sm text-gray-600">Where <span class="font-mono">γ</span> is the discount factor, which balances immediate and future rewards.</p>
                            </div>
                            <div>
                                <h4 class="font-semibold text-lg mb-2">Q-Table Update (C)</h4>
                                <pre><code class="language-c">
// Simplified C implementation for a single Q-learning update step.
#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;

#define NUM_STATES 10
#define NUM_ACTIONS 4

// Q-table: stores the expected rewards for an action in a state
double Q_table[NUM_STATES][NUM_ACTIONS];

// Hyperparameters
double alpha = 0.1; // Learning rate
double gamma = 0.9; // Discount factor

// Function to find the max Q-value for the next state
double getMaxQ(int next_state) {
    double max_q = -1.0 / 0.0; // Negative infinity
    for (int i = 0; i < NUM_ACTIONS; i++) {
        if (Q_table[next_state][i] > max_q) {
            max_q = Q_table[next_state][i];
        }
    }
    return max_q;
}

// Update the Q-table based on an experience
void updateQ_table(int state, int action, double reward, int next_state) {
    // Q(s, a) = Q(s, a) + α * [R + γ * max_a' Q(s', a') - Q(s, a)]
    
    // 1. Get max Q-value for the next state
    double max_q_next = getMaxQ(next_state);
    
    // 2. Calculate the target value
    double target = reward + gamma * max_q_next;
    
    // 3. Calculate the update value (TD Error * learning rate)
    double update_val = alpha * (target - Q_table[state][action]);

    // 4. Update the Q-value for the current state-action pair
    Q_table[state][action] += update_val;
}
                                </code></pre>
                            </div>
                        </div>
                    </div>
                </div>
            </section>

            <section id="content-research" class="content-section">
                <div class="bg-white p-6 sm:p-8 rounded-xl shadow-md">
                    <h2 class="text-2xl font-bold text-gray-800 mb-4">Global Research & Applications</h2>
                    <p class="text-gray-700 mb-6 leading-relaxed">
                        The principles of adaptive AI/ML control are being explored and applied globally. This section highlights relevant research and applications from leading institutions and companies in key technology hubs. The information is presented in the local language to reflect the source, with an English translation available.
                    </p>

                    <div class="flex items-center justify-between border-b border-gray-200 mb-6">
                         <div class="flex items-center space-x-2 overflow-x-auto pb-2">
                            <div id="sub-nav-il" class="sub-nav-item sub-nav-item-active">Israel</div>
                            <div id="sub-nav-cn" class="sub-nav-item">China</div>
                            <div id="sub-nav-ch" class="sub-nav-item">Switzerland</div>
                            <div id="sub-nav-uk" class="sub-nav-item">United Kingdom</div>
                        </div>
                        <div class="flex items-center space-x-2 flex-shrink-0 pl-4">
                            <span class="text-sm font-medium text-gray-600">Translate</span>
                            <label for="translation-toggle" class="inline-flex items-center cursor-pointer">
                              <span class="relative">
                                <input type="checkbox" id="translation-toggle" class="sr-only peer">
                                <div class="w-10 h-6 bg-gray-200 rounded-full peer peer-checked:after:translate-x-full peer-checked:after:border-white after:content-[''] after:absolute after:top-0.5 after:left-[2px] after:bg-white after:border-gray-300 after:border after:rounded-full after:h-5 after:w-5 after:transition-all peer-checked:bg-blue-600"></div>
                              </span>
                            </label>
                        </div>
                    </div>

                    <div id="tab-content-il" class="tab-content tab-content-active">
                        <h3 class="text-xl font-semibold mb-1">Source: Weizmann Institute of Science AI Lab</h3>
                        <p class="text-sm text-gray-500 mb-4">Application Area: Autonomous Drone Swarm Coordination</p>
                        <div class="p-4 border rounded-lg bg-slate-50">
                            <p class="lang-original text-lg" lang="he" dir="rtl">שימוש בלמידת חיזוק עמוקה לתיאום נחילי רחפנים אוטונומיים במשימות חיפוש והצלה. המודל מאפשר לרחפנים ללמוד אסטרטגיות שיתוף פעולה אדפטיביות בזמן אמת, תוך התחשבות במצבי סוללה משתנים ותנאי סביבה דינמיים, כדי למקסם את כיסוי השטח.</p>
                            <p class="lang-translation text-gray-700 mt-2 hidden">Using deep reinforcement learning to coordinate autonomous drone swarms in search and rescue missions. The model allows drones to learn adaptive collaboration strategies in real-time, considering variable battery states and dynamic environmental conditions to maximize area coverage.</p>
                        </div>
                    </div>

                    <div id="tab-content-cn" class="tab-content">
                        <h3 class="text-xl font-semibold mb-1">Source: Tsinghua University, Institute for AI Industry Research</h3>
                        <p class="text-sm text-gray-500 mb-4">Application Area: Smart Grid Energy Management</p>
                        <div class="p-4 border rounded-lg bg-slate-50">
                            <p class="lang-original text-lg" lang="zh">应用基于LSTM和强化学习的混合模型对智能电网的能源需求进行预测和调度。该框架能够动态调整能源分配策略，以应对可再生能源（如太阳能和风能）的波动性，从而提高电网的稳定性和效率。</p>
                            <p class="lang-translation text-gray-700 mt-2 hidden">Application of a hybrid model based on LSTM and reinforcement learning for energy demand prediction and scheduling in smart grids. The framework can dynamically adjust energy distribution strategies to cope with the volatility of renewable energy sources (like solar and wind), thereby improving grid stability and efficiency.</p>
                        </div>
                    </div>
                    
                    <div id="tab-content-ch" class="tab-content">
                        <h3 class="text-xl font-semibold mb-1">Source: ETH Zürich, Automatic Control Laboratory</h3>
                        <p class="text-sm text-gray-500 mb-4">Application Area: High-Precision Manufacturing Robotics</p>
                        <div class="p-4 border rounded-lg bg-slate-50">
                            <p class="lang-original text-lg" lang="de">Implementierung eines adaptiven Regelungsrahmens für Roboterarme in der Präzisionsfertigung. Das System nutzt prädiktive Modelle, um thermische Ausdehnung und Werkzeugverschleiss vorherzusagen, und ein RL-Agent passt die Roboterbahn kontinuierlich an, um eine Genauigkeit im Sub-Millimeter-Bereich aufrechtzuerhalten.</p>
                            <p class="lang-translation text-gray-700 mt-2 hidden">Implementation of an adaptive control framework for robotic arms in precision manufacturing. The system uses predictive models to anticipate thermal expansion and tool wear, and an RL agent continuously adjusts the robot's trajectory to maintain sub-millimeter accuracy.</p>
                        </div>
                    </div>

                    <div id="tab-content-uk" class="tab-content">
                        <h3 class="text-xl font-semibold mb-1">Source: University of Cambridge, Machine Intelligence Laboratory</h3>
                        <p class="text-sm text-gray-500 mb-4">Application Area: Personalized Medicine Dosage Control</p>
                        <div class="p-4 border rounded-lg bg-slate-50">
                            <p class="lang-original text-lg" lang="en">Developing a control framework for automated insulin delivery systems in Type 1 diabetes management. An LSTM model predicts future blood glucose levels based on sensor data and meal information, while an RL agent determines optimal insulin infusion rates, creating a personalized and adaptive artificial pancreas.</p>
                            <p class="lang-translation text-gray-700 mt-2 hidden">Developing a control framework for automated insulin delivery systems in Type 1 diabetes management. An LSTM model predicts future blood glucose levels based on sensor data and meal information, while an RL agent determines optimal insulin infusion rates, creating a personalized and adaptive artificial pancreas.</p>
                        </div>
                    </div>

                </div>
            </section>
        </main>
    </div>

    <script>
        document.addEventListener('DOMContentLoaded', function () {
            const appState = {
                activeNav: 'intro',
                activeModelTab: 'lstm',
                activeResearchTab: 'il'
            };

            const navItems = document.querySelectorAll('.nav-item');
            const contentSections = document.querySelectorAll('.content-section');
            const modelSubNavItems = document.querySelectorAll('#content-models .sub-nav-item');
            const modelTabContents = document.querySelectorAll('#content-models .tab-content');
            const researchSubNavItems = document.querySelectorAll('#content-research .sub-nav-item');
            const researchTabContents = document.querySelectorAll('#content-research .tab-content');
            
            const translationToggle = document.getElementById('translation-toggle');

            function updateNav() {
                navItems.forEach(item => {
                    if (item.id === `nav-${appState.activeNav}`) {
                        item.classList.add('nav-item-active');
                    } else {
                        item.classList.remove('nav-item-active');
                    }
                });

                contentSections.forEach(section => {
                    if (section.id === `content-${appState.activeNav}`) {
                        section.classList.add('content-section-active');
                    } else {
                        section.classList.remove('content-section-active');
                    }
                });
            }

            function updateModelTabs() {
                modelSubNavItems.forEach(item => {
                    item.classList.toggle('sub-nav-item-active', item.id === `sub-nav-${appState.activeModelTab}`);
                });
                modelTabContents.forEach(content => {
                    content.classList.toggle('tab-content-active', content.id === `tab-content-${appState.activeModelTab}`);
                });
            }

            function updateResearchTabs() {
                researchSubNavItems.forEach(item => {
                    item.classList.toggle('sub-nav-item-active', item.id === `sub-nav-${appState.activeResearchTab}`);
                });
                researchTabContents.forEach(content => {
                    content.classList.toggle('tab-content-active', content.id === `tab-content-${appState.activeResearchTab}`);
                });
            }

            navItems.forEach(item => {
                item.addEventListener('click', () => {
                    appState.activeNav = item.id.split('-')[1];
                    updateNav();
                });
            });

            modelSubNavItems.forEach(item => {
                item.addEventListener('click', () => {
                    appState.activeModelTab = item.id.split('-')[2];
                    updateModelTabs();
                });
            });

            researchSubNavItems.forEach(item => {
                item.addEventListener('click', () => {
                    appState.activeResearchTab = item.id.split('-')[2];
                    updateResearchTabs();
                });
            });
            
            translationToggle.addEventListener('change', (event) => {
                const showTranslation = event.target.checked;
                document.querySelectorAll('.lang-original').forEach(el => {
                    el.classList.toggle('hidden', showTranslation);
                });
                document.querySelectorAll('.lang-translation').forEach(el => {
                    el.classList.toggle('hidden', !showTranslation);
                });
            });


            const actualData = [12, 19, 3, 5, 2, 3, 7, 8, 11, 14, 13, 10, 15, 18, 17, 16, 20, 22, 21, 19];
            const predictionData = [19.5, 17.5, 16.5, 18, 21, 22.5];
            const labels = Array.from({ length: actualData.length + predictionData.length }, (_, i) => `T${i + 1}`);

            const chartCtx = document.getElementById('lstmChart').getContext('2d');
            const lstmChart = new Chart(chartCtx, {
                type: 'line',
                data: {
                    labels: labels,
                    datasets: [{
                        label: 'Actual System Data',
                        data: actualData,
                        borderColor: 'rgb(59, 130, 246)',
                        backgroundColor: 'rgba(59, 130, 246, 0.5)',
                        tension: 0.1
                    }]
                },
                options: {
                    responsive: true,
                    maintainAspectRatio: false,
                    scales: {
                        y: {
                            beginAtZero: true,
                             grid: { color: '#e5e7eb' }
                        },
                        x: {
                             grid: { color: '#e5e7eb' }
                        }
                    },
                    plugins: {
                        legend: { position: 'top' },
                        title: { display: true, text: 'System Performance Over Time' }
                    }
                }
            });

            document.getElementById('runPredictionBtn').addEventListener('click', () => {
                if (lstmChart.data.datasets.length > 1) {
                    lstmChart.data.datasets.pop();
                }
                 
                setTimeout(() => {
                    const predictedDataset = {
                        label: 'LSTM Predicted Data',
                        data: Array(actualData.length - 1).fill(null).concat([actualData[actualData.length - 1]], predictionData),
                        borderColor: 'rgb(236, 72, 153)',
                        backgroundColor: 'rgba(236, 72, 153, 0.5)',
                        borderDash: [5, 5],
                        tension: 0.1
                    };
                    lstmChart.data.datasets.push(predictedDataset);
                    lstmChart.update();
                }, 200);
            });

            function renderKatex() {
                katex.render("f_t = \\sigma(W_f \\cdot [h_{t-1}, x_t] + b_f)", document.getElementById('forget-gate'), { throwOnError: false, displayMode: true });
                katex.render("i_t = \\sigma(W_i \\cdot [h_{t-1}, x_t] + b_i)", document.getElementById('input-gate'), { throwOnError: false, displayMode: true });
                katex.render("C_t = f_t \\odot C_{t-1} + i_t \\odot \\tanh(W_C \\cdot [h_{t-1}, x_t] + b_C)", document.getElementById('cell-state'), { throwOnError: false, displayMode: true });
                katex.render("h_t = \\sigma(W_o \\cdot [h_{t-1}, x_t] + b_o) \\odot \\tanh(C_t)", document.getElementById('output-gate'), { throwOnError: false, displayMode: true });
                katex.render("Q(s,a) \\leftarrow Q(s,a) + \\alpha [R + \\gamma \\max_{a'} Q(s',a') - Q(s,a)]", document.getElementById('bellman-eq'), { throwOnError: false, displayMode: true });
            }
            
            renderKatex();
            updateNav();
        });
    </script>
</body>
</html>
